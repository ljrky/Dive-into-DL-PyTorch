{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用词向量搜索近义词和类比词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于PyTorch的关于自然语言处理的常用包有官方的torchtext以及第三方的pytorch-nlp等等\n",
    "\n",
    "import torch\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "vocab.pretrained_aliases.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.42B.300d',\n",
       " 'glove.840B.300d',\n",
       " 'glove.twitter.27B.25d',\n",
       " 'glove.twitter.27B.50d',\n",
       " 'glove.twitter.27B.100d',\n",
       " 'glove.twitter.27B.200d',\n",
       " 'glove.6B.50d',\n",
       " 'glove.6B.100d',\n",
       " 'glove.6B.200d',\n",
       " 'glove.6B.300d']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预训练的GloVe模型的命名规范大致是“模型.（数据集.）数据集词数.词向量维度”。\n",
    "# 更多信息可以参考GloVe和fastText的项目网站[1,2]。下面我们使用基于维基百科子集预训练的50维GloVe词向量。\n",
    "# 第一次创建预训练词向量实例时会自动下载相应的词向量到cache指定文件夹（默认为.vector_cache），因此需要联网。\n",
    "\n",
    "[key for key in vocab.pretrained_aliases.keys()\n",
    "        if \"glove\" in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"C:/Users/ljrky/Datasets/glove\"\n",
    "# glove = vocab.pretrained_aliases[\"glove.6B.50d\"](cache=cache_dir)\n",
    "glove = vocab.GloVe(name='6B', dim=50, cache=cache_dir) # 与上面等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共包含400000个词。\n"
     ]
    }
   ],
   "source": [
    "print(\"一共包含%d个词。\" % len(glove.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3366, 'beautiful')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.stoi['beautiful'], glove.itos[3366] # (3366, 'beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # 添加的1e-9是为了数值稳定性\n",
    "    cos = torch.matmul(W, x.view((-1,))) / (\n",
    "        (torch.sum(W * W, dim=1) + 1e-9).sqrt() * torch.sum(x * x).sqrt())\n",
    "    _, topk = torch.topk(cos, k=k)\n",
    "    topk = topk.cpu().numpy()\n",
    "    return topk, [cos[i].item() for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    topk, cos = knn(embed.vectors,\n",
    "                    embed.vectors[embed.stoi[query_token]], k+1)\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # 除去输入词\n",
    "        print('cosine sim=%.3f: %s' % (c, (embed.itos[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求同义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.856: chips\n",
      "cosine sim=0.749: intel\n",
      "cosine sim=0.749: electronics\n"
     ]
    }
   ],
   "source": [
    "# 搜索与“chip”语义最相近的3个词\n",
    "get_similar_tokens('chip', 3, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to baby\n",
      "cosine sim=0.839: babies\n",
      "cosine sim=0.800: boy\n",
      "cosine sim=0.792: girl\n",
      "similar to beautiful\n",
      "cosine sim=0.921: lovely\n",
      "cosine sim=0.893: gorgeous\n",
      "cosine sim=0.830: wonderful\n"
     ]
    }
   ],
   "source": [
    "# 接下来查找“baby”和“beautiful”的近义词。\n",
    "print(\"similar to baby\")\n",
    "get_similar_tokens('baby', 3, glove)\n",
    "print(\"similar to beautiful\")\n",
    "get_similar_tokens('beautiful', 3, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求类比词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除了求近义词以外，我们还可以使用预训练词向量求词与词之间的类比关系。\n",
    "# 例如，“man”（男人）: “woman”（女人）:: “son”（儿子） : “daughter”（女儿）是一个类比例子：\n",
    "# “man”之于“woman”相当于“son”之于“daughter”。\n",
    "# 求类比词问题可以定义为：对于类比关系中的4个词 a:b::c:da:b::c:d，给定前3个词aa、bb和cc，求dd。\n",
    "# 设词ww的词向量为vec(w)vec(w)。求类比词的思路是，搜索与vec(c)+vec(b)−vec(a)vec(c)+vec(b)−vec(a)的结果向量最相似的词向量。\n",
    "\n",
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = [embed.vectors[embed.stoi[t]] \n",
    "                for t in [token_a, token_b, token_c]]\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.vectors, x, 1)\n",
    "    return embed.itos[topk[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daughter'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'son', glove) # 'daughter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove) # 'japan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biggest'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove) # 'biggest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('do', 'did', 'go', glove) # 'went'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
